package analytics

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"sync"
	"time"

	"go.uber.org/zap"
)

// DashboardService service de dashboard temps r√©el
type DashboardService struct {
	db                     *sql.DB
	logger                 *zap.Logger
	cache                  EngagementCache
	userEngagementService  *UserEngagementService
	chatAnalyticsService   *ChatAnalyticsService
	streamAnalyticsService *StreamAnalyticsService
	revenueAnalyticsService *RevenueAnalyticsService
	
	// WebSocket pour updates temps r√©el
	subscribers map[string]chan *DashboardUpdate
	mutex       sync.RWMutex
	
	// M√©triques en cache
	cachedMetrics *DashboardMetrics
	lastUpdate    time.Time
}

// DashboardMetrics m√©triques compl√®tes du dashboard
type DashboardMetrics struct {
	Overview          OverviewMetrics           `json:"overview"`
	UserEngagement    *UserEngagementMetrics    `json:"user_engagement"`
	ChatMetrics       *ChatMetrics              `json:"chat_metrics"`
	StreamMetrics     *StreamMetrics            `json:"stream_metrics"`
	RevenueMetrics    *RevenueMetrics           `json:"revenue_metrics"`
	RealtimeMetrics   RealtimeMetrics           `json:"realtime_metrics"`
	SystemHealth      SystemHealthMetrics       `json:"system_health"`
	AlertsAndNotifications []DashboardAlert     `json:"alerts_notifications"`
	LastUpdated       time.Time                 `json:"last_updated"`
}

// OverviewMetrics m√©triques de vue d'ensemble
type OverviewMetrics struct {
	TotalUsers        int64   `json:"total_users"`
	ActiveUsers24h    int64   `json:"active_users_24h"`
	TotalRevenue      float64 `json:"total_revenue"`
	Revenue24h        float64 `json:"revenue_24h"`
	TotalStreams      int64   `json:"total_streams"`
	Streams24h        int64   `json:"streams_24h"`
	TotalMessages     int64   `json:"total_messages"`
	Messages24h       int64   `json:"messages_24h"`
	ConversionRate    float64 `json:"conversion_rate"`
	ChurnRate         float64 `json:"churn_rate"`
	NPS               float64 `json:"nps"`                // Net Promoter Score
	ServerUptime      float64 `json:"server_uptime"`
}

// RealtimeMetrics m√©triques temps r√©el
type RealtimeMetrics struct {
	CurrentUsers      int64                 `json:"current_users"`
	ActiveStreams     int64                 `json:"active_streams"`
	MessageRate       float64               `json:"message_rate_per_minute"`
	StreamRate        float64               `json:"stream_rate_per_minute"`
	ErrorRate         float64               `json:"error_rate_percent"`
	ResponseTime      float64               `json:"avg_response_time_ms"`
	BandwidthUsage    float64               `json:"bandwidth_usage_mbps"`
	CPUUsage          float64               `json:"cpu_usage_percent"`
	MemoryUsage       float64               `json:"memory_usage_percent"`
	DatabaseQueries   int64                 `json:"database_queries_per_second"`
	CacheHitRate      float64               `json:"cache_hit_rate_percent"`
	ActiveConnections int64                 `json:"active_connections"`
	QueueLength       int64                 `json:"queue_length"`
	GeoDistribution   map[string]int64      `json:"geo_distribution"`
}

// SystemHealthMetrics m√©triques de sant√© du syst√®me
type SystemHealthMetrics struct {
	OverallHealth     string                 `json:"overall_health"`      // healthy, warning, critical
	Services          map[string]ServiceHealth `json:"services"`
	Infrastructure    InfrastructureHealth   `json:"infrastructure"`
	Alerts            []SystemAlert          `json:"alerts"`
	LastIncident      *time.Time             `json:"last_incident,omitempty"`
	UptimePercentage  float64                `json:"uptime_percentage"`
}

// ServiceHealth sant√© d'un service
type ServiceHealth struct {
	Status        string    `json:"status"`         // healthy, warning, critical, down
	ResponseTime  float64   `json:"response_time_ms"`
	ErrorRate     float64   `json:"error_rate_percent"`
	LastCheck     time.Time `json:"last_check"`
	Dependencies  []string  `json:"dependencies"`
}

// InfrastructureHealth sant√© de l'infrastructure
type InfrastructureHealth struct {
	Database      ServiceHealth `json:"database"`
	Redis         ServiceHealth `json:"redis"`
	FileStorage   ServiceHealth `json:"file_storage"`
	CDN           ServiceHealth `json:"cdn"`
	LoadBalancer  ServiceHealth `json:"load_balancer"`
	Monitoring    ServiceHealth `json:"monitoring"`
}

// SystemAlert alerte syst√®me
type SystemAlert struct {
	ID          string    `json:"id"`
	Severity    string    `json:"severity"`    // info, warning, critical
	Service     string    `json:"service"`
	Message     string    `json:"message"`
	Timestamp   time.Time `json:"timestamp"`
	Resolved    bool      `json:"resolved"`
	ResolvedAt  *time.Time `json:"resolved_at,omitempty"`
}

// DashboardAlert alerte dashboard
type DashboardAlert struct {
	ID          string    `json:"id"`
	Type        string    `json:"type"`        // metric_threshold, anomaly, system
	Severity    string    `json:"severity"`
	Title       string    `json:"title"`
	Description string    `json:"description"`
	Metric      string    `json:"metric"`
	Threshold   float64   `json:"threshold"`
	CurrentValue float64  `json:"current_value"`
	Timestamp   time.Time `json:"timestamp"`
	Acknowledged bool     `json:"acknowledged"`
}

// DashboardUpdate update temps r√©el du dashboard
type DashboardUpdate struct {
	Type      string      `json:"type"`      // full_refresh, metric_update, alert
	Data      interface{} `json:"data"`
	Timestamp time.Time   `json:"timestamp"`
}

// DashboardConfig configuration du dashboard
type DashboardConfig struct {
	RefreshInterval time.Duration `json:"refresh_interval"`
	AlertThresholds AlertThresholds `json:"alert_thresholds"`
	EnableRealtime  bool          `json:"enable_realtime"`
}

// AlertThresholds seuils d'alerte
type AlertThresholds struct {
	HighErrorRate        float64 `json:"high_error_rate"`         // %
	HighResponseTime     float64 `json:"high_response_time"`      // ms
	LowConversionRate    float64 `json:"low_conversion_rate"`     // %
	HighChurnRate        float64 `json:"high_churn_rate"`         // %
	LowCacheHitRate      float64 `json:"low_cache_hit_rate"`      // %
	HighCPUUsage         float64 `json:"high_cpu_usage"`          // %
	HighMemoryUsage      float64 `json:"high_memory_usage"`       // %
	LowDiskSpace         float64 `json:"low_disk_space"`          // %
}

// NewDashboardService cr√©e un nouveau service de dashboard
func NewDashboardService(
	db *sql.DB,
	logger *zap.Logger,
	cache EngagementCache,
	userEngagementService *UserEngagementService,
	chatAnalyticsService *ChatAnalyticsService,
	streamAnalyticsService *StreamAnalyticsService,
	revenueAnalyticsService *RevenueAnalyticsService,
) *DashboardService {
	return &DashboardService{
		db:                      db,
		logger:                  logger,
		cache:                   cache,
		userEngagementService:   userEngagementService,
		chatAnalyticsService:    chatAnalyticsService,
		streamAnalyticsService:  streamAnalyticsService,
		revenueAnalyticsService: revenueAnalyticsService,
		subscribers:             make(map[string]chan *DashboardUpdate),
	}
}

// Start d√©marre le service de dashboard
func (s *DashboardService) Start(ctx context.Context, config *DashboardConfig) {
	if config == nil {
		config = &DashboardConfig{
			RefreshInterval: 30 * time.Second,
			EnableRealtime:  true,
			AlertThresholds: AlertThresholds{
				HighErrorRate:     5.0,
				HighResponseTime:  1000.0,
				LowConversionRate: 2.0,
				HighChurnRate:     10.0,
				LowCacheHitRate:   80.0,
				HighCPUUsage:      80.0,
				HighMemoryUsage:   85.0,
				LowDiskSpace:      90.0,
			},
		}
	}

	s.logger.Info("üöÄ Starting dashboard service",
		zap.Duration("refresh_interval", config.RefreshInterval),
		zap.Bool("realtime_enabled", config.EnableRealtime))

	// Worker de mise √† jour des m√©triques
	go s.metricsUpdateWorker(ctx, config)

	// Worker de d√©tection d'alertes
	go s.alertWorker(ctx, config)

	// Worker de nettoyage des abonn√©s
	go s.cleanupWorker(ctx)
}

// GetDashboardMetrics retourne les m√©triques compl√®tes du dashboard
func (s *DashboardService) GetDashboardMetrics(ctx context.Context, dateRange DateRange) (*DashboardMetrics, error) {
	// V√©rifier le cache
	if s.cachedMetrics != nil && time.Since(s.lastUpdate) < 30*time.Second {
		return s.cachedMetrics, nil
	}

	metrics := &DashboardMetrics{}

	// Collecter toutes les m√©triques en parall√®le
	var wg sync.WaitGroup
	var mu sync.Mutex
	errors := make([]error, 0)

	// Overview
	wg.Add(1)
	go func() {
		defer wg.Done()
		overview, err := s.getOverviewMetrics(ctx, dateRange)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("overview metrics: %w", err))
			mu.Unlock()
			return
		}
		metrics.Overview = overview
	}()

	// User Engagement
	wg.Add(1)
	go func() {
		defer wg.Done()
		userMetrics, err := s.userEngagementService.GetEngagementMetrics(ctx, dateRange)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("user engagement: %w", err))
			mu.Unlock()
			return
		}
		metrics.UserEngagement = userMetrics
	}()

	// Chat Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		chatMetrics, err := s.chatAnalyticsService.GetChatMetrics(ctx, dateRange)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("chat metrics: %w", err))
			mu.Unlock()
			return
		}
		metrics.ChatMetrics = chatMetrics
	}()

	// Stream Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		streamMetrics, err := s.streamAnalyticsService.GetStreamMetrics(ctx, dateRange)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("stream metrics: %w", err))
			mu.Unlock()
			return
		}
		metrics.StreamMetrics = streamMetrics
	}()

	// Revenue Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		revenueMetrics, err := s.revenueAnalyticsService.GetRevenueMetrics(ctx, dateRange)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("revenue metrics: %w", err))
			mu.Unlock()
			return
		}
		metrics.RevenueMetrics = revenueMetrics
	}()

	// Realtime Metrics
	wg.Add(1)
	go func() {
		defer wg.Done()
		realtimeMetrics, err := s.getRealtimeMetrics(ctx)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("realtime metrics: %w", err))
			mu.Unlock()
			return
		}
		metrics.RealtimeMetrics = realtimeMetrics
	}()

	// System Health
	wg.Add(1)
	go func() {
		defer wg.Done()
		systemHealth, err := s.getSystemHealth(ctx)
		if err != nil {
			mu.Lock()
			errors = append(errors, fmt.Errorf("system health: %w", err))
			mu.Unlock()
			return
		}
		metrics.SystemHealth = systemHealth
	}()

	wg.Wait()

	// V√©rifier les erreurs
	if len(errors) > 0 {
		s.logger.Error("Errors collecting dashboard metrics", zap.Any("errors", errors))
		// Continuer avec les m√©triques partielles
	}

	// Alertes
	alerts, err := s.getActiveAlerts(ctx)
	if err != nil {
		s.logger.Error("Failed to get alerts", zap.Error(err))
	} else {
		metrics.AlertsAndNotifications = alerts
	}

	metrics.LastUpdated = time.Now()

	// Mettre en cache
	s.cachedMetrics = metrics
	s.lastUpdate = time.Now()

	return metrics, nil
}

// SubscribeToUpdates s'abonne aux mises √† jour temps r√©el
func (s *DashboardService) SubscribeToUpdates(subscriberID string) chan *DashboardUpdate {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	channel := make(chan *DashboardUpdate, 100)
	s.subscribers[subscriberID] = channel

	s.logger.Debug("New dashboard subscriber", zap.String("subscriber_id", subscriberID))

	return channel
}

// UnsubscribeFromUpdates se d√©sabonne des mises √† jour
func (s *DashboardService) UnsubscribeFromUpdates(subscriberID string) {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if channel, exists := s.subscribers[subscriberID]; exists {
		close(channel)
		delete(s.subscribers, subscriberID)
		s.logger.Debug("Dashboard subscriber removed", zap.String("subscriber_id", subscriberID))
	}
}

// BroadcastUpdate diffuse une mise √† jour √† tous les abonn√©s
func (s *DashboardService) BroadcastUpdate(update *DashboardUpdate) {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	for subscriberID, channel := range s.subscribers {
		select {
		case channel <- update:
		default:
			s.logger.Warn("Dashboard update channel full", zap.String("subscriber_id", subscriberID))
		}
	}
}

// ============================================================================
// WORKERS ET M√âTHODES PRIV√âES
// ============================================================================

// metricsUpdateWorker met √† jour les m√©triques p√©riodiquement
func (s *DashboardService) metricsUpdateWorker(ctx context.Context, config *DashboardConfig) {
	ticker := time.NewTicker(config.RefreshInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.updateMetrics(ctx)
		}
	}
}

// alertWorker surveille les m√©triques et g√©n√®re des alertes
func (s *DashboardService) alertWorker(ctx context.Context, config *DashboardConfig) {
	ticker := time.NewTicker(1 * time.Minute) // V√©rification toutes les minutes
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.checkAlerts(ctx, config.AlertThresholds)
		}
	}
}

// cleanupWorker nettoie les abonn√©s inactifs
func (s *DashboardService) cleanupWorker(ctx context.Context) {
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.cleanupInactiveSubscribers()
		}
	}
}

// updateMetrics met √† jour toutes les m√©triques
func (s *DashboardService) updateMetrics(ctx context.Context) {
	dateRange := DateRange{
		Start: time.Now().AddDate(0, 0, -1), // Derni√®res 24h
		End:   time.Now(),
	}

	metrics, err := s.GetDashboardMetrics(ctx, dateRange)
	if err != nil {
		s.logger.Error("Failed to update dashboard metrics", zap.Error(err))
		return
	}

	// Diffuser la mise √† jour
	update := &DashboardUpdate{
		Type:      "full_refresh",
		Data:      metrics,
		Timestamp: time.Now(),
	}

	s.BroadcastUpdate(update)
}

// getOverviewMetrics r√©cup√®re les m√©triques de vue d'ensemble
func (s *DashboardService) getOverviewMetrics(ctx context.Context, dateRange DateRange) (OverviewMetrics, error) {
	overview := OverviewMetrics{}

	// Requ√™tes parall√®les pour les m√©triques de base
	var wg sync.WaitGroup
	var mu sync.Mutex

	// Total utilisateurs
	wg.Add(1)
	go func() {
		defer wg.Done()
		var count int64
		query := `SELECT COUNT(*) FROM users`
		s.db.QueryRowContext(ctx, query).Scan(&count)
		mu.Lock()
		overview.TotalUsers = count
		mu.Unlock()
	}()

	// Utilisateurs actifs 24h
	wg.Add(1)
	go func() {
		defer wg.Done()
		var count int64
		query := `SELECT COUNT(DISTINCT user_id) FROM user_sessions WHERE start_time >= $1`
		s.db.QueryRowContext(ctx, query, time.Now().AddDate(0, 0, -1)).Scan(&count)
		mu.Lock()
		overview.ActiveUsers24h = count
		mu.Unlock()
	}()

	// Revenus 24h
	wg.Add(1)
	go func() {
		defer wg.Done()
		var revenue sql.NullFloat64
		query := `
			SELECT COALESCE(SUM(amount), 0) 
			FROM revenue_transactions 
			WHERE timestamp >= $1 AND status = 'completed' AND type != 'refund'`
		s.db.QueryRowContext(ctx, query, time.Now().AddDate(0, 0, -1)).Scan(&revenue)
		mu.Lock()
		if revenue.Valid {
			overview.Revenue24h = revenue.Float64
		}
		mu.Unlock()
	}()

	wg.Wait()

	// M√©triques calcul√©es
	overview.ConversionRate = 15.5 // TODO: Calculer le vrai taux
	overview.ChurnRate = 3.8       // TODO: Calculer le vrai taux
	overview.NPS = 72.0            // TODO: Int√©grer avec un syst√®me de feedback
	overview.ServerUptime = 99.95  // TODO: Calculer depuis le monitoring

	return overview, nil
}

// getRealtimeMetrics r√©cup√®re les m√©triques temps r√©el
func (s *DashboardService) getRealtimeMetrics(ctx context.Context) (RealtimeMetrics, error) {
	// M√©triques simul√©es - dans un vrai syst√®me, ces donn√©es viendraient
	// d'un syst√®me de monitoring comme Prometheus, New Relic, etc.
	return RealtimeMetrics{
		CurrentUsers:      245,
		ActiveStreams:     67,
		MessageRate:       15.8,
		StreamRate:        4.2,
		ErrorRate:         0.12,
		ResponseTime:      45.7,
		BandwidthUsage:    125.6,
		CPUUsage:          34.8,
		MemoryUsage:       52.1,
		DatabaseQueries:   187,
		CacheHitRate:      94.3,
		ActiveConnections: 1250,
		QueueLength:       12,
		GeoDistribution: map[string]int64{
			"France": 85,
			"Belgium": 42,
			"Switzerland": 38,
			"Canada": 35,
			"Germany": 28,
			"UK": 17,
		},
	}, nil
}

// getSystemHealth r√©cup√®re l'√©tat de sant√© du syst√®me
func (s *DashboardService) getSystemHealth(ctx context.Context) (SystemHealthMetrics, error) {
	// Simulation des checks de sant√©
	return SystemHealthMetrics{
		OverallHealth:    "healthy",
		UptimePercentage: 99.95,
		Services: map[string]ServiceHealth{
			"api": {
				Status:       "healthy",
				ResponseTime: 45.2,
				ErrorRate:    0.12,
				LastCheck:    time.Now(),
			},
			"websocket": {
				Status:       "healthy",
				ResponseTime: 15.8,
				ErrorRate:    0.05,
				LastCheck:    time.Now(),
			},
			"streaming": {
				Status:       "healthy",
				ResponseTime: 78.5,
				ErrorRate:    0.23,
				LastCheck:    time.Now(),
			},
		},
		Infrastructure: InfrastructureHealth{
			Database: ServiceHealth{
				Status:       "healthy",
				ResponseTime: 12.5,
				ErrorRate:    0.01,
				LastCheck:    time.Now(),
			},
			Redis: ServiceHealth{
				Status:       "healthy",
				ResponseTime: 2.3,
				ErrorRate:    0.0,
				LastCheck:    time.Now(),
			},
		},
	}, nil
}

// getActiveAlerts r√©cup√®re les alertes actives
func (s *DashboardService) getActiveAlerts(ctx context.Context) ([]DashboardAlert, error) {
	// TODO: Int√©grer avec un vrai syst√®me d'alertes
	return []DashboardAlert{}, nil
}

// checkAlerts v√©rifie les seuils d'alerte
func (s *DashboardService) checkAlerts(ctx context.Context, thresholds AlertThresholds) {
	// TODO: Impl√©menter la logique de v√©rification des alertes
}

// cleanupInactiveSubscribers nettoie les abonn√©s inactifs
func (s *DashboardService) cleanupInactiveSubscribers() {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	// TODO: Impl√©menter le nettoyage bas√© sur l'activit√©
}
